{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T09:06:05.366014Z",
     "iopub.status.busy": "2023-01-19T09:06:05.365235Z",
     "iopub.status.idle": "2023-01-19T09:06:05.386802Z",
     "shell.execute_reply": "2023-01-19T09:06:05.385895Z",
     "shell.execute_reply.started": "2023-01-19T09:06:05.365925Z"
    },
    "id": "7025daa3"
   },
   "outputs": [],
   "source": [
    "# !conda install --yes numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T09:06:05.389637Z",
     "iopub.status.busy": "2023-01-19T09:06:05.388941Z",
     "iopub.status.idle": "2023-01-19T09:06:07.045253Z",
     "shell.execute_reply": "2023-01-19T09:06:07.044209Z",
     "shell.execute_reply.started": "2023-01-19T09:06:05.389599Z"
    },
    "id": "649fbe8a"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T09:06:07.047054Z",
     "iopub.status.busy": "2023-01-19T09:06:07.046503Z",
     "iopub.status.idle": "2023-01-19T09:06:07.122306Z",
     "shell.execute_reply": "2023-01-19T09:06:07.121326Z",
     "shell.execute_reply.started": "2023-01-19T09:06:07.047017Z"
    },
    "id": "d2de7787",
    "outputId": "52d91b11-ea36-4e76-b53b-3092d702ada4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T09:06:07.126156Z",
     "iopub.status.busy": "2023-01-19T09:06:07.125769Z",
     "iopub.status.idle": "2023-01-19T09:06:08.108972Z",
     "shell.execute_reply": "2023-01-19T09:06:08.107911Z",
     "shell.execute_reply.started": "2023-01-19T09:06:07.126130Z"
    },
    "id": "5d06685d",
    "outputId": "5aaec605-bb09-4670-eeb6-66bd3b22a73c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan 19 09:06:07 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   37C    P0    27W / 250W |      2MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T09:06:08.111418Z",
     "iopub.status.busy": "2023-01-19T09:06:08.110692Z",
     "iopub.status.idle": "2023-01-19T09:06:58.556925Z",
     "shell.execute_reply": "2023-01-19T09:06:58.555704Z",
     "shell.execute_reply.started": "2023-01-19T09:06:08.111379Z"
    },
    "id": "5f7813f7",
    "outputId": "487960ec-dcf5-4a05-d82e-dd0e9df98f2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (2.1.0)\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (5.0.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.21.6)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (4.64.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2022.11.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from datasets) (22.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (4.13.0)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (2.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.7.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.13.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.7.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.12.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torchaudio in /opt/conda/lib/python3.7/site-packages (0.11.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from torchaudio) (1.11.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch->torchaudio) (4.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: librosa in /opt/conda/lib/python3.7/site-packages (0.9.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.7/site-packages (from librosa) (1.0.1)\n",
      "Requirement already satisfied: decorator>=4.0.10 in /opt/conda/lib/python3.7/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from librosa) (1.0.2)\n",
      "Requirement already satisfied: numba>=0.45.1 in /opt/conda/lib/python3.7/site-packages (from librosa) (0.55.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from librosa) (22.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.7/site-packages (from librosa) (1.21.6)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.7/site-packages (from librosa) (3.0.0)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from librosa) (1.7.3)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from librosa) (0.4.2)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in /opt/conda/lib/python3.7/site-packages (from librosa) (0.11.0)\n",
      "Requirement already satisfied: pooch>=1.0 in /opt/conda/lib/python3.7/site-packages (from librosa) (1.6.0)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /opt/conda/lib/python3.7/site-packages (from numba>=0.45.1->librosa) (0.38.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from numba>=0.45.1->librosa) (59.8.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from pooch>=1.0->librosa) (2.28.1)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from pooch>=1.0->librosa) (1.4.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.19.1->librosa) (3.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.7/site-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.12.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting jiwer\n",
      "  Downloading jiwer-2.5.1-py3-none-any.whl (15 kB)\n",
      "Collecting levenshtein==0.20.2\n",
      "  Downloading Levenshtein-0.20.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hRequirement already satisfied: rapidfuzz<3.0.0,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from levenshtein==0.20.2->jiwer) (2.13.7)\n",
      "Installing collected packages: levenshtein, jiwer\n",
      "  Attempting uninstall: levenshtein\n",
      "    Found existing installation: Levenshtein 0.20.9\n",
      "    Uninstalling Levenshtein-0.20.9:\n",
      "      Successfully uninstalled Levenshtein-0.20.9\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "python-levenshtein 0.20.9 requires Levenshtein==0.20.9, but you have levenshtein 0.20.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed jiwer-2.5.1 levenshtein-0.20.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "!pip3 install datasets\n",
    "!pip3 install transformers\n",
    "!pip3 install torchaudio\n",
    "!pip3 install librosa\n",
    "!pip3 install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T09:06:58.559429Z",
     "iopub.status.busy": "2023-01-19T09:06:58.558605Z",
     "iopub.status.idle": "2023-01-19T09:13:22.300923Z",
     "shell.execute_reply": "2023-01-19T09:13:22.299940Z",
     "shell.execute_reply.started": "2023-01-19T09:06:58.559397Z"
    },
    "id": "9be015c3",
    "outputId": "3d6732b7-f3cd-4ca6-c4a2-3350038aed00"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a27b7dd04a42c8882915ebfcf5f727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9f3295a098d40ef8feb3c23e6cf597e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/11.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset common_voice/ru (download: 3.40 GiB, generated: 4.88 GiB, post-processed: Unknown size, total: 8.29 GiB) to /root/.cache/huggingface/datasets/common_voice/ru/6.1.0/7cd6a2cd99f885b3ec1205a6aee65d9b8c7b36a2c0f482fa4a1dde3d29860f21...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c34f87caf76438298c995d180fb2afc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/15481 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/8007 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/7963 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating other split:   0%|          | 0/10247 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validated split:   0%|          | 0/74256 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating invalidated split:   0%|          | 0/3056 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset common_voice downloaded and prepared to /root/.cache/huggingface/datasets/common_voice/ru/6.1.0/7cd6a2cd99f885b3ec1205a6aee65d9b8c7b36a2c0f482fa4a1dde3d29860f21. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric, Audio\n",
    "\n",
    "common_voice_train = load_dataset(\"common_voice\", \"ru\", split=\"train+validation\")\n",
    "common_voice_test = load_dataset(\"common_voice\", \"ru\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T09:13:22.303109Z",
     "iopub.status.busy": "2023-01-19T09:13:22.302550Z",
     "iopub.status.idle": "2023-01-19T09:13:22.314472Z",
     "shell.execute_reply": "2023-01-19T09:13:22.313630Z",
     "shell.execute_reply.started": "2023-01-19T09:13:22.303071Z"
    },
    "id": "24f927e8"
   },
   "outputs": [],
   "source": [
    "common_voice_train = common_voice_train.remove_columns([\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"segment\", \"up_votes\"])\n",
    "common_voice_test = common_voice_test.remove_columns([\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"segment\", \"up_votes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T09:13:22.316435Z",
     "iopub.status.busy": "2023-01-19T09:13:22.316061Z",
     "iopub.status.idle": "2023-01-19T09:13:22.327002Z",
     "shell.execute_reply": "2023-01-19T09:13:22.326022Z",
     "shell.execute_reply.started": "2023-01-19T09:13:22.316396Z"
    },
    "id": "13b9a38b"
   },
   "outputs": [],
   "source": [
    "from datasets import ClassLabel\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T09:13:22.329179Z",
     "iopub.status.busy": "2023-01-19T09:13:22.328268Z",
     "iopub.status.idle": "2023-01-19T09:13:22.337278Z",
     "shell.execute_reply": "2023-01-19T09:13:22.336338Z",
     "shell.execute_reply.started": "2023-01-19T09:13:22.329143Z"
    },
    "id": "7069ed7e"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\%\\‘\\”\\�]'\n",
    "\n",
    "def remove_special_characters(batch):\n",
    "    batch[\"sentence\"] = re.sub(chars_to_ignore_regex, '', batch[\"sentence\"]).lower() + \" \"\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T09:13:22.342081Z",
     "iopub.status.busy": "2023-01-19T09:13:22.341771Z",
     "iopub.status.idle": "2023-01-19T09:13:40.192264Z",
     "shell.execute_reply": "2023-01-19T09:13:40.191055Z",
     "shell.execute_reply.started": "2023-01-19T09:13:22.342055Z"
    },
    "id": "6a0b9875",
    "outputId": "affce52b-ce25-4b45-ad53-d014cd102e4c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ac8f05b13648f4a39ba0da33e6639e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23444 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc88fe292abc416f9137fd8f52e51c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8007 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "common_voice_train = common_voice_train.map(remove_special_characters)\n",
    "common_voice_test = common_voice_test.map(remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T09:13:40.196620Z",
     "iopub.status.busy": "2023-01-19T09:13:40.196258Z",
     "iopub.status.idle": "2023-01-19T09:13:40.283191Z",
     "shell.execute_reply": "2023-01-19T09:13:40.282123Z",
     "shell.execute_reply.started": "2023-01-19T09:13:40.196590Z"
    },
    "id": "512c08f4",
    "outputId": "67256744-5da2-4411-eb30-c18071782777"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>мы ненадолго извините</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>конференция по разоружению утратила убедительность в качестве единого многостороннего форума по разоружению и нераспространению</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>темпы годового прироста вкладов населения в банках достигли минимального уровня за последние пять лет</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>но наш регион не может расти и двигаться вперед отдельно от других</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>наша приверженность борьбе против табака остается непоколебимой</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>как я вижу слова только что попросил посол мексики</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>мы принимаем к сведению ваши заключительные замечания</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>я кратко выскажу то о чем обязан сказать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>я также хочу ответить на ложные беспочвенные и неправомерные утверждения в отношении этих островов</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>по мнению бельгии и нидерландов такая ситуация сохраняться больше не может</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(common_voice_train.remove_columns([\"path\",\"audio\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T09:13:40.285481Z",
     "iopub.status.busy": "2023-01-19T09:13:40.285068Z",
     "iopub.status.idle": "2023-01-19T09:15:28.820537Z",
     "shell.execute_reply": "2023-01-19T09:15:28.818757Z",
     "shell.execute_reply.started": "2023-01-19T09:13:40.285443Z"
    },
    "id": "OKO59QsDUakr",
    "outputId": "793caee4-c09c-4813-a616-72f303f8f5b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-01-19 09:13:43--  https://downloader.disk.yandex.ru/disk/d25e4558b7a19cbe9197bee41992d8dc24b5875267aab0bde69843a503eabe13/63c92b28/SAFtUcwKI0ZrxCUQ5i2Bv7CpBsn1qzqtgE63ze8uzDtIJdB8c2w6L9H5KASWJheUq9dPlaVh7iA1sMqQVp0-yA%3D%3D?uid=0&filename=model.zip&disposition=attachment&hash=wlsHaIodv6q7Duj95SGiolqQI7lxoMYKDd0yw9hwJMVDwNKUsjIXFtNiPUUC9FR0q/J6bpmRyOJonT3VoXnDag%3D%3D&limit=0&content_type=application%2Fzip&owner_uid=1482923029&fsize=344969172&hid=d513d22ec211e37069e3d7bc10b9599c&media_type=compressed&tknv=v2\n",
      "Resolving downloader.disk.yandex.ru (downloader.disk.yandex.ru)... 77.88.21.127, 2a02:6b8::2:127\n",
      "Connecting to downloader.disk.yandex.ru (downloader.disk.yandex.ru)|77.88.21.127|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://s340vla.storage.yandex.net/rdisk/d25e4558b7a19cbe9197bee41992d8dc24b5875267aab0bde69843a503eabe13/63c92b28/SAFtUcwKI0ZrxCUQ5i2Bv7CpBsn1qzqtgE63ze8uzDtIJdB8c2w6L9H5KASWJheUq9dPlaVh7iA1sMqQVp0-yA==?uid=0&filename=model.zip&disposition=attachment&hash=wlsHaIodv6q7Duj95SGiolqQI7lxoMYKDd0yw9hwJMVDwNKUsjIXFtNiPUUC9FR0q/J6bpmRyOJonT3VoXnDag%3D%3D&limit=0&content_type=application%2Fzip&owner_uid=1482923029&fsize=344969172&hid=d513d22ec211e37069e3d7bc10b9599c&media_type=compressed&tknv=v2&rtoken=NHeMXNVdW0C1&force_default=no&ycrid=na-ff3d8c90e2cfdfbc6b01f603b70395bb-downloader10h&ts=5f29c56c31a00&s=ff1b39d873b6826170a8a04e29d9c3711fce85322852b988f556873693376404&pb=U2FsdGVkX1_G4b7yDnpEDWwWpjSNtGyHbrPUwxiEFT9hLSmkc-GQWPcoFZ_H0dsB3DcmY0gLjDFUCfolgC-Qg1oabMnnKg5oWUG4ayq6btQ [following]\n",
      "--2023-01-19 09:13:45--  https://s340vla.storage.yandex.net/rdisk/d25e4558b7a19cbe9197bee41992d8dc24b5875267aab0bde69843a503eabe13/63c92b28/SAFtUcwKI0ZrxCUQ5i2Bv7CpBsn1qzqtgE63ze8uzDtIJdB8c2w6L9H5KASWJheUq9dPlaVh7iA1sMqQVp0-yA==?uid=0&filename=model.zip&disposition=attachment&hash=wlsHaIodv6q7Duj95SGiolqQI7lxoMYKDd0yw9hwJMVDwNKUsjIXFtNiPUUC9FR0q/J6bpmRyOJonT3VoXnDag%3D%3D&limit=0&content_type=application%2Fzip&owner_uid=1482923029&fsize=344969172&hid=d513d22ec211e37069e3d7bc10b9599c&media_type=compressed&tknv=v2&rtoken=NHeMXNVdW0C1&force_default=no&ycrid=na-ff3d8c90e2cfdfbc6b01f603b70395bb-downloader10h&ts=5f29c56c31a00&s=ff1b39d873b6826170a8a04e29d9c3711fce85322852b988f556873693376404&pb=U2FsdGVkX1_G4b7yDnpEDWwWpjSNtGyHbrPUwxiEFT9hLSmkc-GQWPcoFZ_H0dsB3DcmY0gLjDFUCfolgC-Qg1oabMnnKg5oWUG4ayq6btQ\n",
      "Resolving s340vla.storage.yandex.net (s340vla.storage.yandex.net)... 141.8.128.64, 2a02:6b8:c0e:9cc:0:41af:8268:ab5b\n",
      "Connecting to s340vla.storage.yandex.net (s340vla.storage.yandex.net)|141.8.128.64|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 344969172 (329M) [application/zip]\n",
      "Saving to: ‘model.zip’\n",
      "\n",
      "model.zip           100%[===================>] 328.99M  17.0MB/s    in 97s     \n",
      "\n",
      "2023-01-19 09:15:24 (3.40 MB/s) - ‘model.zip’ saved [344969172/344969172]\n",
      "\n",
      "Archive:  model.zip\n",
      "   creating: pretrained/model/\n",
      "  inflating: pretrained/model/config.json  \n",
      "  inflating: pretrained/model/preprocessor_config.json  \n",
      "  inflating: pretrained/model/pytorch_model.bin  \n",
      "  inflating: pretrained/model/rng_state.pth  \n",
      "  inflating: pretrained/model/scaler.pt  \n",
      "  inflating: pretrained/model/scheduler.pt  \n",
      "  inflating: pretrained/model/trainer_state.json  \n",
      "  inflating: pretrained/model/training_args.bin  \n"
     ]
    }
   ],
   "source": [
    "!mkdir pretrained\n",
    "!wget -O model.zip \"https://downloader.disk.yandex.ru/disk/d25e4558b7a19cbe9197bee41992d8dc24b5875267aab0bde69843a503eabe13/63c92b28/SAFtUcwKI0ZrxCUQ5i2Bv7CpBsn1qzqtgE63ze8uzDtIJdB8c2w6L9H5KASWJheUq9dPlaVh7iA1sMqQVp0-yA%3D%3D?uid=0&filename=model.zip&disposition=attachment&hash=wlsHaIodv6q7Duj95SGiolqQI7lxoMYKDd0yw9hwJMVDwNKUsjIXFtNiPUUC9FR0q/J6bpmRyOJonT3VoXnDag%3D%3D&limit=0&content_type=application%2Fzip&owner_uid=1482923029&fsize=344969172&hid=d513d22ec211e37069e3d7bc10b9599c&media_type=compressed&tknv=v2\"\n",
    "!unzip -o model.zip -d pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T09:15:44.011007Z",
     "iopub.status.busy": "2023-01-19T09:15:44.010607Z",
     "iopub.status.idle": "2023-01-19T09:15:44.022007Z",
     "shell.execute_reply": "2023-01-19T09:15:44.020793Z",
     "shell.execute_reply.started": "2023-01-19T09:15:44.010973Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "vocab_dict1 = {\"m\": 0, \"\\u0451\": 1, \"e\": 2, \"i\": 3, \"\\u0436\": 4, \"\\u2011\": 5, \"s\": 6, \"\\u044f\": 7, \"\\u0440\": 8, \"\\u043c\": 9, \"\\u043d\": 10, \"\\u00ab\": 11, \"\\u0439\": 12, \"g\": 13, \"\\u0442\": 14, \"\\u2013\": 15, \"k\": 16, \"z\": 17, \"\\u2014\": 18, \"\\u0437\": 19, \"'\": 20, \"a\": 21, \"\\u0434\": 22, \"\\u043b\": 23, \"\\u00bb\": 24, \"\\u0447\": 25, \"\\u0441\": 26, \"\\u0431\": 27, \"h\": 28, \"c\": 29, \"(\": 30, \"\\u0438\": 31, \"l\": 32, \"\\u0449\": 33, \"\\u0444\": 34, \"o\": 35, \"\\u0448\": 36, \"\\u0443\": 37, \"\\u0445\": 38, \"\\u0433\": 39, \"\\u0446\": 40, \"\\u2026\": 41, \"\\u044b\": 42, \"b\": 43, \"x\": 44, \"\\u043e\": 45, \"\\u044d\": 46, \"\\u044a\": 47, \"p\": 48, \"\\u0430\": 49, \"\\u043f\": 50, \"\\u044e\": 51, \"\\u2212\": 52, \"\\u0435\": 53, \"\\u0432\": 54, \"\\u044c\": 55, \"r\": 57, \"t\": 58, \"\\u043a\": 59, \")\": 60, \"f\": 61, \"n\": 62, \"|\": 56, \"[UNK]\": 63, \"[PAD]\": 64}\n",
    "with open('vocab1.json', 'w') as vocab_file:\n",
    "    json.dump(vocab_dict1, vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T09:15:46.004865Z",
     "iopub.status.busy": "2023-01-19T09:15:46.004170Z",
     "iopub.status.idle": "2023-01-19T09:15:46.012871Z",
     "shell.execute_reply": "2023-01-19T09:15:46.011951Z",
     "shell.execute_reply.started": "2023-01-19T09:15:46.004828Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'m': 0,\n",
       " 'ё': 1,\n",
       " 'e': 2,\n",
       " 'i': 3,\n",
       " 'ж': 4,\n",
       " '‑': 5,\n",
       " 's': 6,\n",
       " 'я': 7,\n",
       " 'р': 8,\n",
       " 'м': 9,\n",
       " 'н': 10,\n",
       " '«': 11,\n",
       " 'й': 12,\n",
       " 'g': 13,\n",
       " 'т': 14,\n",
       " '–': 15,\n",
       " 'k': 16,\n",
       " 'z': 17,\n",
       " '—': 18,\n",
       " 'з': 19,\n",
       " \"'\": 20,\n",
       " 'a': 21,\n",
       " 'д': 22,\n",
       " 'л': 23,\n",
       " '»': 24,\n",
       " 'ч': 25,\n",
       " 'с': 26,\n",
       " 'б': 27,\n",
       " 'h': 28,\n",
       " 'c': 29,\n",
       " '(': 30,\n",
       " 'и': 31,\n",
       " 'l': 32,\n",
       " 'щ': 33,\n",
       " 'ф': 34,\n",
       " 'o': 35,\n",
       " 'ш': 36,\n",
       " 'у': 37,\n",
       " 'х': 38,\n",
       " 'г': 39,\n",
       " 'ц': 40,\n",
       " '…': 41,\n",
       " 'ы': 42,\n",
       " 'b': 43,\n",
       " 'x': 44,\n",
       " 'о': 45,\n",
       " 'э': 46,\n",
       " 'ъ': 47,\n",
       " 'p': 48,\n",
       " 'а': 49,\n",
       " 'п': 50,\n",
       " 'ю': 51,\n",
       " '−': 52,\n",
       " 'е': 53,\n",
       " 'в': 54,\n",
       " 'ь': 55,\n",
       " 'r': 57,\n",
       " 't': 58,\n",
       " 'к': 59,\n",
       " ')': 60,\n",
       " 'f': 61,\n",
       " 'n': 62,\n",
       " '|': 56,\n",
       " '[UNK]': 63,\n",
       " '[PAD]': 64}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T09:15:49.468614Z",
     "iopub.status.busy": "2023-01-19T09:15:49.468236Z",
     "iopub.status.idle": "2023-01-19T09:15:49.838733Z",
     "shell.execute_reply": "2023-01-19T09:15:49.837622Z",
     "shell.execute_reply.started": "2023-01-19T09:15:49.468584Z"
    },
    "id": "f8ec3841"
   },
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2CTCTokenizer\n",
    "\n",
    "tokenizer = Wav2Vec2CTCTokenizer(\"/kaggle/working/vocab1.json\", unk_token=\"[UNK]\", pad_token=\"[PAD]\", word_delimiter_token=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T09:15:50.876117Z",
     "iopub.status.busy": "2023-01-19T09:15:50.875138Z",
     "iopub.status.idle": "2023-01-19T09:15:50.885278Z",
     "shell.execute_reply": "2023-01-19T09:15:50.884212Z",
     "shell.execute_reply.started": "2023-01-19T09:15:50.876081Z"
    },
    "id": "545352e0"
   },
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2FeatureExtractor\n",
    "\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T09:15:53.523799Z",
     "iopub.status.busy": "2023-01-19T09:15:53.523185Z",
     "iopub.status.idle": "2023-01-19T09:15:53.534653Z",
     "shell.execute_reply": "2023-01-19T09:15:53.533680Z",
     "shell.execute_reply.started": "2023-01-19T09:15:53.523767Z"
    },
    "id": "ab57915e"
   },
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Processor\n",
    "\n",
    "processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T09:15:55.049939Z",
     "iopub.status.busy": "2023-01-19T09:15:55.049567Z",
     "iopub.status.idle": "2023-01-19T09:15:55.063281Z",
     "shell.execute_reply": "2023-01-19T09:15:55.062240Z",
     "shell.execute_reply.started": "2023-01-19T09:15:55.049908Z"
    },
    "id": "66cbaa5a"
   },
   "outputs": [],
   "source": [
    "common_voice_train = common_voice_train.cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "common_voice_test = common_voice_test.cast_column(\"audio\", Audio(sampling_rate=16_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T09:16:19.610612Z",
     "iopub.status.busy": "2023-01-19T09:16:19.610149Z",
     "iopub.status.idle": "2023-01-19T09:16:19.620744Z",
     "shell.execute_reply": "2023-01-19T09:16:19.618260Z",
     "shell.execute_reply.started": "2023-01-19T09:16:19.610575Z"
    },
    "id": "a9e8c2ac"
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # batched output is \"un-batched\"\n",
    "    batch[\"input_values\"] = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_values[0]\n",
    "    \n",
    "    with processor.as_target_processor():\n",
    "        batch[\"labels\"] = processor(batch[\"sentence\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T09:16:21.755388Z",
     "iopub.status.busy": "2023-01-19T09:16:21.754635Z",
     "iopub.status.idle": "2023-01-19T09:16:21.759900Z",
     "shell.execute_reply": "2023-01-19T09:16:21.758970Z",
     "shell.execute_reply.started": "2023-01-19T09:16:21.755349Z"
    },
    "id": "3b8c5931"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T09:16:27.218219Z",
     "iopub.status.busy": "2023-01-19T09:16:27.217863Z",
     "iopub.status.idle": "2023-01-19T09:16:27.225278Z",
     "shell.execute_reply": "2023-01-19T09:16:27.224079Z",
     "shell.execute_reply.started": "2023-01-19T09:16:27.218189Z"
    },
    "id": "8600e12f",
    "outputId": "20ccc7c0-7869-45f6-e32a-aa67b4d66a47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T09:16:33.623086Z",
     "iopub.status.busy": "2023-01-19T09:16:33.622710Z",
     "iopub.status.idle": "2023-01-19T09:24:16.127497Z",
     "shell.execute_reply": "2023-01-19T09:24:16.126112Z",
     "shell.execute_reply.started": "2023-01-19T09:16:33.623054Z"
    },
    "id": "17298840",
    "outputId": "6e1c6742-6b66-43e1-9a7d-f5a3e4331574"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0111761436c54788a95a2c9d12174f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23444 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f644a51389940aab8c50dddc4eee979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8007 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "common_voice_train = common_voice_train.map(prepare_dataset, remove_columns=common_voice_train.column_names, num_proc=1)\n",
    "common_voice_test = common_voice_test.map(prepare_dataset, remove_columns=common_voice_test.column_names, num_proc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T09:24:16.130699Z",
     "iopub.status.busy": "2023-01-19T09:24:16.129884Z",
     "iopub.status.idle": "2023-01-19T09:24:16.158391Z",
     "shell.execute_reply": "2023-01-19T09:24:16.154903Z",
     "shell.execute_reply.started": "2023-01-19T09:24:16.130662Z"
    },
    "id": "30ed554e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received.\n",
    "    Args:\n",
    "        processor (:class:`~transformers.Wav2Vec2Processor`)\n",
    "            The processor used for proccessing the data.\n",
    "        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n",
    "            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
    "            among:\n",
    "            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n",
    "              sequence if provided).\n",
    "            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n",
    "              maximum acceptable input length for the model if that argument is not provided.\n",
    "            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n",
    "              different lengths).\n",
    "        max_length (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``input_values`` of the returned list and optionally padding length (see above).\n",
    "        max_length_labels (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``labels`` returned list and optionally padding length (see above).\n",
    "        pad_to_multiple_of (:obj:`int`, `optional`):\n",
    "            If set will pad the sequence to a multiple of the provided value.\n",
    "            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n",
    "            7.5 (Volta).\n",
    "    \"\"\"\n",
    "\n",
    "    processor: Wav2Vec2Processor\n",
    "    padding: Union[bool, str] = True\n",
    "    max_length: Optional[int] = None\n",
    "    max_length_labels: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    pad_to_multiple_of_labels: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lenghts and need\n",
    "        # different padding methods\n",
    "        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "\n",
    "        batch = self.processor.pad(\n",
    "            input_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        with self.processor.as_target_processor():\n",
    "            labels_batch = self.processor.pad(\n",
    "                label_features,\n",
    "                padding=self.padding,\n",
    "                max_length=self.max_length_labels,\n",
    "                pad_to_multiple_of=self.pad_to_multiple_of_labels,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T09:24:16.162378Z",
     "iopub.status.busy": "2023-01-19T09:24:16.161970Z",
     "iopub.status.idle": "2023-01-19T09:24:17.306233Z",
     "shell.execute_reply": "2023-01-19T09:24:17.305051Z",
     "shell.execute_reply.started": "2023-01-19T09:24:16.162339Z"
    },
    "id": "41985125"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T09:24:17.310624Z",
     "iopub.status.busy": "2023-01-19T09:24:17.309007Z",
     "iopub.status.idle": "2023-01-19T09:24:18.188513Z",
     "shell.execute_reply": "2023-01-19T09:24:18.187561Z",
     "shell.execute_reply.started": "2023-01-19T09:24:17.310595Z"
    },
    "id": "d42c6562",
    "outputId": "060d99af-9cb2-443e-9a4f-c91cc03c5843"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e6ab42396644d87a79456e1d348b833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.90k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wer_metric = load_metric(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T09:24:18.190108Z",
     "iopub.status.busy": "2023-01-19T09:24:18.189778Z",
     "iopub.status.idle": "2023-01-19T09:24:18.198157Z",
     "shell.execute_reply": "2023-01-19T09:24:18.196554Z",
     "shell.execute_reply.started": "2023-01-19T09:24:18.190076Z"
    },
    "id": "4963d8c9"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
    "\n",
    "    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
    "\n",
    "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T09:24:18.200414Z",
     "iopub.status.busy": "2023-01-19T09:24:18.199953Z",
     "iopub.status.idle": "2023-01-19T09:24:22.286882Z",
     "shell.execute_reply": "2023-01-19T09:24:22.285553Z",
     "shell.execute_reply.started": "2023-01-19T09:24:18.200379Z"
    },
    "id": "adf99206"
   },
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2ForCTC\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    \"/kaggle/working/pretrained/model\", \n",
    "    attention_dropout=0.1,\n",
    "    hidden_dropout=0.1,\n",
    "    feat_proj_dropout=0.0,\n",
    "    mask_time_prob=0.05,\n",
    "    layerdrop=0.1,\n",
    "    ctc_loss_reduction=\"mean\", \n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    "    vocab_size=len(processor.tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T09:24:22.291641Z",
     "iopub.status.busy": "2023-01-19T09:24:22.290545Z",
     "iopub.status.idle": "2023-01-19T09:24:22.300177Z",
     "shell.execute_reply": "2023-01-19T09:24:22.298780Z",
     "shell.execute_reply.started": "2023-01-19T09:24:22.291597Z"
    },
    "id": "1b45cb10",
    "outputId": "94391f1b-ce87-44ce-d98b-ea7cddf9ba06"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1619: FutureWarning: The method `freeze_feature_extractor` is deprecated and will be removed in Transformers v5.Please use the equivalent `freeze_feature_encoder` method instead.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "model.freeze_feature_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T09:24:22.302667Z",
     "iopub.status.busy": "2023-01-19T09:24:22.302172Z",
     "iopub.status.idle": "2023-01-19T09:24:22.310319Z",
     "shell.execute_reply": "2023-01-19T09:24:22.308955Z",
     "shell.execute_reply.started": "2023-01-19T09:24:22.302629Z"
    },
    "id": "677dd703"
   },
   "outputs": [],
   "source": [
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3c1537d8"
   },
   "source": [
    "batch_size=20- загрузка 10гб первая карта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T09:24:22.312662Z",
     "iopub.status.busy": "2023-01-19T09:24:22.312268Z",
     "iopub.status.idle": "2023-01-19T09:24:22.362272Z",
     "shell.execute_reply": "2023-01-19T09:24:22.361232Z",
     "shell.execute_reply.started": "2023-01-19T09:24:22.312626Z"
    },
    "id": "c1582654"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  # output_dir=\"/content/gdrive/MyDrive/wav2vec2-large-xlsr-turkish-demo\",\n",
    "  output_dir=\"./wav2vec2-basee-ru-demo\",\n",
    "  group_by_length=True,\n",
    "  per_device_train_batch_size=25,\n",
    "  gradient_accumulation_steps=16,\n",
    "  evaluation_strategy=\"steps\",\n",
    "  num_train_epochs=100,\n",
    "  fp16=True,\n",
    "  save_steps=50,\n",
    "  eval_steps=25,\n",
    "  logging_steps=10,\n",
    "  learning_rate=1e-4,\n",
    "  #warmup_steps=500,\n",
    "  save_total_limit=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T09:24:22.367688Z",
     "iopub.status.busy": "2023-01-19T09:24:22.367206Z",
     "iopub.status.idle": "2023-01-19T09:24:28.208349Z",
     "shell.execute_reply": "2023-01-19T09:24:28.207353Z",
     "shell.execute_reply.started": "2023-01-19T09:24:22.367662Z"
    },
    "id": "6a5baf4f",
    "outputId": "7fd3594a-f31e-4f20-cf80-f1189b0736f9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=common_voice_train.with_format(\"torch\"),\n",
    "    eval_dataset=common_voice_test.with_format(\"torch\"),\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T11:59:13.290022Z",
     "iopub.status.busy": "2023-01-19T11:59:13.288995Z",
     "iopub.status.idle": "2023-01-19T11:59:13.298736Z",
     "shell.execute_reply": "2023-01-19T11:59:13.296360Z",
     "shell.execute_reply.started": "2023-01-19T11:59:13.289983Z"
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T09:24:28.221047Z",
     "iopub.status.busy": "2023-01-19T09:24:28.220782Z",
     "iopub.status.idle": "2023-01-19T11:53:46.371127Z",
     "shell.execute_reply": "2023-01-19T11:53:46.363767Z",
     "shell.execute_reply.started": "2023-01-19T09:24:28.221023Z"
    },
    "id": "4a08a98f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 23444\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 25\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 400\n",
      "  Gradient Accumulation steps = 16\n",
      "  Total optimization steps = 5800\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='301' max='5800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 301/5800 2:23:25 < 43:57:54, 0.03 it/s, Epoch 5.17/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.233700</td>\n",
       "      <td>0.507422</td>\n",
       "      <td>0.495476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.224900</td>\n",
       "      <td>0.511023</td>\n",
       "      <td>0.498443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.215000</td>\n",
       "      <td>0.498942</td>\n",
       "      <td>0.491266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.238500</td>\n",
       "      <td>0.504927</td>\n",
       "      <td>0.493404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.251400</td>\n",
       "      <td>0.505427</td>\n",
       "      <td>0.489582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.227300</td>\n",
       "      <td>0.495714</td>\n",
       "      <td>0.491894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.233400</td>\n",
       "      <td>0.496664</td>\n",
       "      <td>0.486975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.229400</td>\n",
       "      <td>0.493352</td>\n",
       "      <td>0.492602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.242000</td>\n",
       "      <td>0.497976</td>\n",
       "      <td>0.486855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.239100</td>\n",
       "      <td>0.486771</td>\n",
       "      <td>0.479237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.239100</td>\n",
       "      <td>0.521131</td>\n",
       "      <td>0.494981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.233800</td>\n",
       "      <td>0.531066</td>\n",
       "      <td>0.500662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.233800</td>\n",
       "      <td>0.531066</td>\n",
       "      <td>0.500662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 8007\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8007\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-basee-ru-demo/checkpoint-50\n",
      "Configuration saved in ./wav2vec2-basee-ru-demo/checkpoint-50/config.json\n",
      "Model weights saved in ./wav2vec2-basee-ru-demo/checkpoint-50/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-basee-ru-demo/checkpoint-50/preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8007\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8007\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-basee-ru-demo/checkpoint-100\n",
      "Configuration saved in ./wav2vec2-basee-ru-demo/checkpoint-100/config.json\n",
      "Model weights saved in ./wav2vec2-basee-ru-demo/checkpoint-100/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-basee-ru-demo/checkpoint-100/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-basee-ru-demo/checkpoint-50] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8007\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8007\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-basee-ru-demo/checkpoint-150\n",
      "Configuration saved in ./wav2vec2-basee-ru-demo/checkpoint-150/config.json\n",
      "Model weights saved in ./wav2vec2-basee-ru-demo/checkpoint-150/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-basee-ru-demo/checkpoint-150/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-basee-ru-demo/checkpoint-100] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8007\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8007\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-basee-ru-demo/checkpoint-200\n",
      "Configuration saved in ./wav2vec2-basee-ru-demo/checkpoint-200/config.json\n",
      "Model weights saved in ./wav2vec2-basee-ru-demo/checkpoint-200/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-basee-ru-demo/checkpoint-200/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-basee-ru-demo/checkpoint-150] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8007\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8007\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-basee-ru-demo/checkpoint-250\n",
      "Configuration saved in ./wav2vec2-basee-ru-demo/checkpoint-250/config.json\n",
      "Model weights saved in ./wav2vec2-basee-ru-demo/checkpoint-250/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-basee-ru-demo/checkpoint-250/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-basee-ru-demo/checkpoint-200] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8007\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8007\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-basee-ru-demo/checkpoint-300\n",
      "Configuration saved in ./wav2vec2-basee-ru-demo/checkpoint-300/config.json\n",
      "Model weights saved in ./wav2vec2-basee-ru-demo/checkpoint-300/pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-basee-ru-demo/checkpoint-300/preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-basee-ru-demo/checkpoint-250] due to args.save_total_limit\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23/4032920361.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1411\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1413\u001b[0;31m             \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1414\u001b[0m         )\n\u001b[1;32m   1415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1649\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1651\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1653\u001b[0m                 if (\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_grad_scaling\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2355\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2356\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_apex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2357\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, насколько модель обучилась (кажется, что не очень)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T11:54:11.685229Z",
     "iopub.status.busy": "2023-01-19T11:54:11.684853Z",
     "iopub.status.idle": "2023-01-19T11:58:09.394198Z",
     "shell.execute_reply": "2023-01-19T11:58:09.393222Z",
     "shell.execute_reply.started": "2023-01-19T11:54:11.685198Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 8007\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5310655236244202, 'eval_wer': 0.5006615966532565}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T12:00:46.129015Z",
     "iopub.status.busy": "2023-01-19T12:00:46.127991Z",
     "iopub.status.idle": "2023-01-19T12:00:46.136338Z",
     "shell.execute_reply": "2023-01-19T12:00:46.134834Z",
     "shell.execute_reply.started": "2023-01-19T12:00:46.128978Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T12:00:48.484121Z",
     "iopub.status.busy": "2023-01-19T12:00:48.483374Z",
     "iopub.status.idle": "2023-01-19T12:04:47.245739Z",
     "shell.execute_reply": "2023-01-19T12:04:47.238230Z",
     "shell.execute_reply.started": "2023-01-19T12:00:48.484085Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /kaggle/working/pretrained/model/config.json\n",
      "Model config Wav2Vec2Config {\n",
      "  \"_name_or_path\": \"./wav2vec2-basee-bachkir-demo/checkpoint-200\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"adapter_kernel_size\": 3,\n",
      "  \"adapter_stride\": 2,\n",
      "  \"add_adapter\": false,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"Wav2Vec2ForCTC\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"codevector_dim\": 256,\n",
      "  \"contrastive_logits_temperature\": 0.1,\n",
      "  \"conv_bias\": false,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"mean\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": false,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"group\",\n",
      "  \"feat_proj_dropout\": 0.0,\n",
      "  \"feat_quantizer_dropout\": 0.0,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"model_type\": \"wav2vec2\",\n",
      "  \"num_adapter_layers\": 3,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_codevector_groups\": 2,\n",
      "  \"num_codevectors_per_group\": 320,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_negatives\": 100,\n",
      "  \"output_hidden_size\": 768,\n",
      "  \"pad_token_id\": 64,\n",
      "  \"proj_codevector_dim\": 256,\n",
      "  \"tdnn_dilation\": [\n",
      "    1,\n",
      "    2,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"tdnn_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    1500\n",
      "  ],\n",
      "  \"tdnn_kernel\": [\n",
      "    5,\n",
      "    3,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 65,\n",
      "  \"xvector_output_dim\": 512\n",
      "}\n",
      "\n",
      "loading weights file /kaggle/working/pretrained/model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing Wav2Vec2ForCTC.\n",
      "\n",
      "All the weights of Wav2Vec2ForCTC were initialized from the model checkpoint at /kaggle/working/pretrained/model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Wav2Vec2ForCTC for predictions without further training.\n",
      "Using cuda_amp half precision backend\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8007\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1001' max='1001' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1001/1001 03:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.49487435817718506,\n",
       " 'eval_wer': 0.4877237065451289,\n",
       " 'eval_runtime': 237.2569,\n",
       " 'eval_samples_per_second': 33.748,\n",
       " 'eval_steps_per_second': 4.219}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_base = Wav2Vec2ForCTC.from_pretrained(\n",
    "    \"/kaggle/working/pretrained/model\", \n",
    "    attention_dropout=0.1,\n",
    "    hidden_dropout=0.1,\n",
    "    feat_proj_dropout=0.0,\n",
    "    mask_time_prob=0.05,\n",
    "    layerdrop=0.1,\n",
    "    ctc_loss_reduction=\"mean\", \n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    "    vocab_size=len(processor.tokenizer)\n",
    ")\n",
    "\n",
    "trainer_base = Trainer(\n",
    "    model=model_base,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=common_voice_train.with_format(\"torch\"),\n",
    "    eval_dataset=common_voice_test.with_format(\"torch\"),\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")\n",
    "\n",
    "trainer_base.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T12:09:13.024717Z",
     "iopub.status.busy": "2023-01-19T12:09:13.024353Z",
     "iopub.status.idle": "2023-01-19T12:09:13.636907Z",
     "shell.execute_reply": "2023-01-19T12:09:13.635804Z",
     "shell.execute_reply.started": "2023-01-19T12:09:13.024686Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save({\n",
    "        'model_state_dict': model.state_dict()\n",
    "}, 'my_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
